[2025-03-18 18:35:38][INFO] Loaded utilities from vitai_scripts package
[2025-03-18 18:35:38][INFO] Loaded 113 patients total from C:\Users\imran\Documents\VITAI\PatientFeatures.csv.
[2025-03-18 18:35:38][DEBUG] Data columns: ['Id', 'AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] Data sample:
                                     Id  ...  INCOME
0  cc8aa0ae-d9c7-388e-c3ee-0893ef011b83  ...       0
1  712331fc-fc49-5f1a-7e40-86d506c3d94c  ...       0
2  2acde8e9-3d73-ff26-b766-f41aa92d120f  ...       0
3  f8c3a8f5-a7f9-5823-7bb0-792af48fcc9b  ...       0
4  737484a5-bdab-66e4-a882-be26c40774a1  ...       0

[5 rows x 8 columns]
[2025-03-18 18:35:38][INFO] Loaded 58 diabetic patients from file
[2025-03-18 18:35:38][INFO] Patient groups => Diabetes=58, CKD=0, None=55
[2025-03-18 18:35:38][INFO] Running model 'combined_diabetes_tabnet' for group 'diabetes' with 58 patients.
[2025-03-18 18:35:38][DEBUG] Group 'diabetes' DataFrame columns: ['Id', 'AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] Group 'diabetes' DataFrame sample:
                                     Id  ...  INCOME
0  cc8aa0ae-d9c7-388e-c3ee-0893ef011b83  ...       0
1  712331fc-fc49-5f1a-7e40-86d506c3d94c  ...       0
2  2acde8e9-3d73-ff26-b766-f41aa92d120f  ...       0

[3 rows x 8 columns]
[2025-03-18 18:35:38][INFO] Found model at: C:\Users\imran\Documents\VITAI\Data\finals\combined_diabetes_tabnet\combined_diabetes_tabnet_model.zip
[2025-03-18 18:35:38][INFO] Loading model combined_diabetes_tabnet on device: cpu
C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\pytorch_tabnet\abstract_model.py:82: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\pytorch_tabnet\abstract_model.py:454: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  saved_state_dict = torch.load(f, map_location=self.device)
[2025-03-18 18:35:38][INFO] Model expects input dimension: 12
[2025-03-18 18:35:38][INFO] Loaded scaler from C:\Users\imran\Documents\VITAI\Data\finals\combined_diabetes_tabnet\combined_diabetes_tabnet_scaler.joblib
[2025-03-18 18:35:38][DEBUG] [combined_diabetes_tabnet] Preprocessing 58 rows with columns: ['Id', 'AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] [combined_diabetes_tabnet] Sample data:
                                     Id  ...  INCOME
0  cc8aa0ae-d9c7-388e-c3ee-0893ef011b83  ...       0
1  712331fc-fc49-5f1a-7e40-86d506c3d94c  ...       0
2  2acde8e9-3d73-ff26-b766-f41aa92d120f  ...       0

[3 rows x 8 columns]
[2025-03-18 18:35:38][DEBUG] [combined_diabetes_tabnet] Numeric feature_cols: ['AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] [combined_diabetes_tabnet] Final shape of X: (58, 7)
[2025-03-18 18:35:38][WARNING] Feature count mismatch! Model expects 12 features but got 7.
[2025-03-18 18:35:38][WARNING] Adding 5 dummy features with zeros.
[2025-03-18 18:35:38][DEBUG] New padded X shape: (58, 12)
[2025-03-18 18:35:38][INFO] Preprocessed features shape: (58, 12) for 58 patients
[2025-03-18 18:35:38][DEBUG] Sample raw features (first row): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[2025-03-18 18:35:38][INFO] Applying scaler to features for model: combined_diabetes_tabnet
C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(
[2025-03-18 18:35:38][ERROR] Error preprocessing features: X has 12 features, but StandardScaler is expecting 7 features as input.
[2025-03-18 18:35:38][ERROR] Traceback (most recent call last):
  File "C:\Users\imran\Documents\VITAI\run_patient_group_predictions.py", line 296, in run_model_for_group
    X = scaler.transform(X)
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\utils\_set_output.py", line 316, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\preprocessing\_data.py", line 1045, in transform
    X = self._validate_data(
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\base.py", line 654, in _validate_data
    self._check_n_features(X, reset=reset)
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\base.py", line 443, in _check_n_features
    raise ValueError(
ValueError: X has 12 features, but StandardScaler is expecting 7 features as input.

[2025-03-18 18:35:38][ERROR] Failed to get predictions for model 'combined_diabetes_tabnet'
[2025-03-18 18:35:38][INFO] No patients in 'ckd' group. Skipping combined_all_ckd_tabnet.
[2025-03-18 18:35:38][INFO] Running model 'combined_none_tabnet' for group 'none' with 55 patients.
[2025-03-18 18:35:38][DEBUG] Group 'none' DataFrame columns: ['Id', 'AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] Group 'none' DataFrame sample:
                                      Id  ...  INCOME
58  258f8fa5-e54d-0498-4d1c-5a4b84e87679  ...       0
59  5585ba2f-ff4a-44ff-8b9b-a2b0fb082830  ...       0
60  d6c03b9f-e066-cc34-f024-6984dddb0881  ...       0

[3 rows x 8 columns]
[2025-03-18 18:35:38][INFO] Found model at: C:\Users\imran\Documents\VITAI\Data\finals\combined_none_tabnet\combined_none_tabnet_model.zip
[2025-03-18 18:35:38][INFO] Loading model combined_none_tabnet on device: cpu
C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\pytorch_tabnet\abstract_model.py:82: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\pytorch_tabnet\abstract_model.py:454: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  saved_state_dict = torch.load(f, map_location=self.device)
[2025-03-18 18:35:38][INFO] Model expects input dimension: 12
[2025-03-18 18:35:38][INFO] Loaded scaler from C:\Users\imran\Documents\VITAI\Data\finals\combined_none_tabnet\combined_none_tabnet_scaler.joblib
[2025-03-18 18:35:38][DEBUG] [combined_none_tabnet] Preprocessing 55 rows with columns: ['Id', 'AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] [combined_none_tabnet] Sample data:
                                      Id  ...  INCOME
58  258f8fa5-e54d-0498-4d1c-5a4b84e87679  ...       0
59  5585ba2f-ff4a-44ff-8b9b-a2b0fb082830  ...       0
60  d6c03b9f-e066-cc34-f024-6984dddb0881  ...       0

[3 rows x 8 columns]
[2025-03-18 18:35:38][DEBUG] [combined_none_tabnet] Numeric feature_cols: ['AGE', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'Hospitalizations_Count', 'Medications_Count', 'Abnormal_Observations_Count', 'INCOME']
[2025-03-18 18:35:38][DEBUG] [combined_none_tabnet] Final shape of X: (55, 7)
[2025-03-18 18:35:38][WARNING] Feature count mismatch! Model expects 12 features but got 7.
[2025-03-18 18:35:38][WARNING] Adding 5 dummy features with zeros.
[2025-03-18 18:35:38][DEBUG] New padded X shape: (55, 12)
[2025-03-18 18:35:38][INFO] Preprocessed features shape: (55, 12) for 55 patients
[2025-03-18 18:35:38][DEBUG] Sample raw features (first row): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[2025-03-18 18:35:38][INFO] Applying scaler to features for model: combined_none_tabnet
C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(
[2025-03-18 18:35:38][ERROR] Error preprocessing features: X has 12 features, but StandardScaler is expecting 7 features as input.
[2025-03-18 18:35:38][ERROR] Traceback (most recent call last):
  File "C:\Users\imran\Documents\VITAI\run_patient_group_predictions.py", line 296, in run_model_for_group
    X = scaler.transform(X)
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\utils\_set_output.py", line 316, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\preprocessing\_data.py", line 1045, in transform
    X = self._validate_data(
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\base.py", line 654, in _validate_data
    self._check_n_features(X, reset=reset)
  File "C:\Users\imran\miniconda3\envs\tf_gpu_env\lib\site-packages\sklearn\base.py", line 443, in _check_n_features
    raise ValueError(
ValueError: X has 12 features, but StandardScaler is expecting 7 features as input.

[2025-03-18 18:35:38][ERROR] Failed to get predictions for model 'combined_none_tabnet'
[2025-03-18 18:35:38][ERROR] Multi-model inference completed with errors.
